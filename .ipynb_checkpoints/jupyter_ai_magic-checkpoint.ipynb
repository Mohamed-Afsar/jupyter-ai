{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e6f1e2-9094-4e93-ae75-874260d969f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae97829c-97fe-4c9e-962b-eab08949710f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a17ea2-b5e9-43e2-9a9a-5195ba2231b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd0d438-75e2-4300-9eb2-4e0f7e159e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] MODEL_ID\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -r, --reset                     Clears the conversation transcript used when\n",
      "                                  interacting with an OpenAI chat model\n",
      "                                  provider. Does nothing with other providers.\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc94991-5db6-4ee5-9865-1b594b2a96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `ai21:j1-large`, `ai21:j1-grande`, `ai21:j1-jumbo`, `ai21:j1-grande-instruct`, `ai21:j2-large`, `ai21:j2-grande`, `ai21:j2-jumbo`, `ai21:j2-grande-instruct`, `ai21:j2-jumbo-instruct` |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | `bedrock:amazon.titan-text-express-v1`, `bedrock:ai21.j2-ultra-v1`, `bedrock:ai21.j2-mid-v1`, `bedrock:cohere.command-text-v14` |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | `bedrock-chat:anthropic.claude-v1`, `bedrock-chat:anthropic.claude-v2`, `bedrock-chat:anthropic.claude-instant-v1` |\n",
       "| `anthropic` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `anthropic:claude-v1`, `anthropic:claude-v1.0`, `anthropic:claude-v1.2`, `anthropic:claude-2`, `anthropic:claude-2.0`, `anthropic:claude-instant-v1`, `anthropic:claude-instant-v1.0`, `anthropic:claude-instant-v1.2` |\n",
       "| `anthropic-chat` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `anthropic-chat:claude-v1`, `anthropic-chat:claude-v1.0`, `anthropic-chat:claude-v1.2`, `anthropic-chat:claude-2`, `anthropic-chat:claude-2.0`, `anthropic-chat:claude-instant-v1`, `anthropic-chat:claude-instant-v1.0`, `anthropic-chat:claude-instant-v1.2` |\n",
       "| `azure-chat-openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `cohere:medium`, `cohere:xlarge` |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | `gpt4all:ggml-gpt4all-j-v1.2-jazzy`, `gpt4all:ggml-gpt4all-j-v1.3-groovy`, `gpt4all:ggml-gpt4all-l13b-snoozy` |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai:text-davinci-003`, `openai:text-davinci-002`, `openai:text-curie-001`, `openai:text-babbage-001`, `openai:text-ada-001`, `openai:davinci`, `openai:curie`, `openai:babbage`, `openai:ada` |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai-chat:gpt-3.5-turbo`, `openai-chat:gpt-3.5-turbo-16k`, `openai-chat:gpt-3.5-turbo-0301`, `openai-chat:gpt-3.5-turbo-0613`, `openai-chat:gpt-3.5-turbo-16k-0613`, `openai-chat:gpt-4`, `openai-chat:gpt-4-0314`, `openai-chat:gpt-4-0613`, `openai-chat:gpt-4-32k`, `openai-chat:gpt-4-32k-0314`, `openai-chat:gpt-4-32k-0613` |\n",
       "| `openai-chat-new` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai-chat-new:gpt-3.5-turbo`, `openai-chat-new:gpt-3.5-turbo-16k`, `openai-chat-new:gpt-3.5-turbo-0301`, `openai-chat-new:gpt-3.5-turbo-0613`, `openai-chat-new:gpt-3.5-turbo-16k-0613`, `openai-chat-new:gpt-4`, `openai-chat-new:gpt-4-0314`, `openai-chat-new:gpt-4-0613`, `openai-chat-new:gpt-4-32k`, `openai-chat-new:gpt-4-32k-0314`, `openai-chat-new:gpt-4-32k-0613` |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:text-davinci-003` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:cohere.command-text-v14\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:anthropic.claude-v1\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "\n",
       "anthropic\n",
       "Requires environment variable ANTHROPIC_API_KEY (not set)\n",
       "* anthropic:claude-v1\n",
       "* anthropic:claude-v1.0\n",
       "* anthropic:claude-v1.2\n",
       "* anthropic:claude-2\n",
       "* anthropic:claude-2.0\n",
       "* anthropic:claude-instant-v1\n",
       "* anthropic:claude-instant-v1.0\n",
       "* anthropic:claude-instant-v1.2\n",
       "\n",
       "anthropic-chat\n",
       "Requires environment variable ANTHROPIC_API_KEY (not set)\n",
       "* anthropic-chat:claude-v1\n",
       "* anthropic-chat:claude-v1.0\n",
       "* anthropic-chat:claude-v1.2\n",
       "* anthropic-chat:claude-2\n",
       "* anthropic-chat:claude-2.0\n",
       "* anthropic-chat:claude-instant-v1\n",
       "* anthropic-chat:claude-instant-v1.0\n",
       "* anthropic-chat:claude-instant-v1.2\n",
       "\n",
       "azure-chat-openai\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "cohere\n",
       "Requires environment variable COHERE_API_KEY (not set)\n",
       "* cohere:medium\n",
       "* cohere:xlarge\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable HUGGINGFACEHUB_API_TOKEN (not set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "openai\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai:text-davinci-003\n",
       "* openai:text-davinci-002\n",
       "* openai:text-curie-001\n",
       "* openai:text-babbage-001\n",
       "* openai:text-ada-001\n",
       "* openai:davinci\n",
       "* openai:curie\n",
       "* openai:babbage\n",
       "* openai:ada\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-16k\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "* openai-chat:gpt-3.5-turbo-0613\n",
       "* openai-chat:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-0314\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0314\n",
       "* openai-chat:gpt-4-32k-0613\n",
       "\n",
       "openai-chat-new\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai-chat-new:gpt-3.5-turbo\n",
       "* openai-chat-new:gpt-3.5-turbo-16k\n",
       "* openai-chat-new:gpt-3.5-turbo-0301\n",
       "* openai-chat-new:gpt-3.5-turbo-0613\n",
       "* openai-chat-new:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat-new:gpt-4\n",
       "* openai-chat-new:gpt-4-0314\n",
       "* openai-chat-new:gpt-4-0613\n",
       "* openai-chat-new:gpt-4-32k\n",
       "* openai-chat-new:gpt-4-32k-0314\n",
       "* openai-chat-new:gpt-4-32k-0613\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:text-davinci-003\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a44e0e-5456-4855-aad6-5fbfa3d072d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai:text-davinci-003`, `openai:text-davinci-002`, `openai:text-curie-001`, `openai:text-babbage-001`, `openai:text-ada-001`, `openai:davinci`, `openai:curie`, `openai:babbage`, `openai:ada` |\n"
      ],
      "text/plain": [
       "openai\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai:text-davinci-003\n",
       "* openai:text-davinci-002\n",
       "* openai:text-curie-001\n",
       "* openai:text-babbage-001\n",
       "* openai:text-ada-001\n",
       "* openai:davinci\n",
       "* openai:curie\n",
       "* openai:babbage\n",
       "* openai:ada\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d676697-bc09-4063-9b3c-49ebfb5dff6d",
   "metadata": {},
   "source": [
    "#### Magic in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4246a4f4-18bf-4307-a7f5-918c3e03b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Lists\n",
       "- Lists are mutable, which means they can be changed after their creation.\n",
       "- Lists are ordered, meaning that the items in a list have a specific order and can be accessed by their index.\n",
       "- Lists can contain duplicate elements.\n",
       "- Lists are represented by square brackets [ ].\n",
       "\n",
       "# Tuples\n",
       "- Tuples are immutable, which means they cannot be modified after their creation.\n",
       "- Tuples are ordered and can be accessed by their index.\n",
       "- Tuples can contain duplicate elements.\n",
       "- Tuples are represented by parentheses ( ).\n",
       "\n",
       "# Sets\n",
       "- Sets are mutable and unordered, which means that the items in a set have no guaranteed order.\n",
       "- Sets do not allow duplicate elements.\n",
       "- Sets are represented by curly braces { }.\n",
       "- Sets can perform set operations like union, intersection, and difference efficiently.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-3.5-turbo\n",
    "lists vs tuples vs sets in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f75db4-8b6c-4b47-a8c4-8d4a1754985f",
   "metadata": {},
   "source": [
    "#### Using alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967cb5b0-0701-47d8-94da-a321cd629ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To sort an array in Swift, you can use the `sorted()` function or the `sort()` method. Here is an example:\n",
       "\n",
       "```swift\n",
       "var array = [5, 2, 9, 1, 3]\n",
       "\n",
       "// Using sorted() function\n",
       "let sortedArray = array.sorted()\n",
       "print(sortedArray)  // Output: [1, 2, 3, 5, 9]\n",
       "\n",
       "// Using sort() method\n",
       "array.sort()\n",
       "print(array)  // Output: [1, 2, 3, 5, 9]\n",
       "```\n",
       "\n",
       "Both the `sorted()` function and `sort()` method return a new array with the elements sorted in ascending order. If you want to sort the array in descending order, you can use the `sorted(by:)` function or the `sort(by:)` method, specifying a custom sorting closure. Here is an example:\n",
       "\n",
       "```swift\n",
       "var array = [5, 2, 9, 1, 3]\n",
       "\n",
       "// Sorting in descending order using sorted(by:) function\n",
       "let sortedArray = array.sorted(by: >)\n",
       "print(sortedArray)  // Output: [9, 5, 3, 2, 1]\n",
       "\n",
       "// Sorting in descending order using sort(by:) method\n",
       "array.sort(by: >)\n",
       "print(array)  // Output: [9, 5, 3, 2, 1]\n",
       "```\n",
       "\n",
       "In this case, the `>` (greater than) operator is used as the sorting closure to sort the array in descending order."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Sorting array in Swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66768242-fc92-4cc5-a35f-38db5c45d4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The `AppDelegate` class is a critical part of an iOS application written in Swift. It serves as the delegate for handling and responding to various system-level events and actions that occur during the lifecycle of the app. Here's a brief explanation of the `AppDelegate` in iOS using Swift:\n",
       "\n",
       "- The `AppDelegate` class is automatically created when you create a new iOS project in Xcode. It represents the overall application instance and acts as the entry point for the app's interactions with the system.\n",
       "\n",
       "- The `AppDelegate` class conforms to the `UIApplicationDelegate` protocol, which defines a set of methods that handle important app-level events such as application launch, termination, background execution, memory warning, etc.\n",
       "\n",
       "- The `AppDelegate` contains several methods, such as `application(_:didFinishLaunchingWithOptions:)`, `applicationWillResignActive(_:)`, `applicationDidEnterBackground(_:)`, `applicationWillEnterForeground(_:)`, and `applicationDidBecomeActive(_:)`, among others.\n",
       "\n",
       "- The `application(_:didFinishLaunchingWithOptions:)` method is called when the app finishes launching, and it provides an opportunity to perform any necessary setup or initialization tasks.\n",
       "\n",
       "- The `applicationWillResignActive(_:)` method is called when the app is about to become inactive, often triggered by events like an incoming call or a user opening the Control Center.\n",
       "\n",
       "- The `applicationDidEnterBackground(_:)` method is called when the app enters the background, allowing you to save any necessary data or perform cleanup tasks.\n",
       "\n",
       "- The `applicationWillEnterForeground(_:)` method is called when the app is about to enter the foreground from the background.\n",
       "\n",
       "- The `applicationDidBecomeActive(_:)` method is called when the app becomes active after being in the background.\n",
       "\n",
       "- You can override these methods in the `AppDelegate` class to add your custom code and respond to specific app-level events.\n",
       "\n",
       "- Additionally, the `AppDelegate` class contains the `window` property, which represents the app's main window and is responsible for presenting the user interface.\n",
       "\n",
       "Overall, the `AppDelegate` class is a crucial component of an iOS app, allowing you to handle system-level events and manage the overall behavior and appearance of the application."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "explain AppDelegate in iOS, Swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ff7a8c-dbe0-4004-a115-5b7e4a59c181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A list in Python is a built-in data structure that represents an ordered collection of elements. It can hold items of different data types, such as numbers, strings, or even other lists. Here's an explanation of lists in Python:\n",
       "\n",
       "- Lists are enclosed in square brackets [ ] and each element is separated by a comma.\n",
       "- Lists are mutable, meaning that their elements can be modified after creation. You can add, remove, or change elements within a list.\n",
       "- Lists can contain elements of different data types. For example, a list can have a combination of integers, strings, or even other lists as its elements.\n",
       "- Lists are ordered, which means that the elements have a specific position or index within the list. The indexing starts from 0, where 0 refers to the first element, 1 refers to the second element, and so on.\n",
       "- Lists allow duplicate elements, which means that the same value can appear multiple times in a list.\n",
       "- Lists support various built-in functions and methods to perform operations such as adding elements, removing elements, sorting, and more.\n",
       "- Lists are versatile and commonly used in Python for tasks like storing collections of data, implementing stacks, queues, and other data structures, iterating over elements, and manipulating data.\n",
       "\n",
       "Example:\n",
       "```python\n",
       "my_list = [1, 2, \"hello\", True, [3, 4, 5]]\n",
       "\n",
       "print(my_list[0])  # Output: 1\n",
       "print(my_list[2])  # Output: hello\n",
       "\n",
       "my_list.append(\"world\")\n",
       "print(my_list)  # Output: [1, 2, \"hello\", True, [3, 4, 5], \"world\"]\n",
       "\n",
       "my_list.remove(2)\n",
       "print(my_list)  # Output: [1, \"hello\", True, [3, 4, 5], \"world\"]\n",
       "```\n",
       "\n",
       "In the example above, we create a list `my_list` with various elements. We access specific elements using indexing, add an element using the `append()` method, and remove an element using the `remove()` method."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai gpt-3.5-turbo\n",
    "Explain list in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1138bd7a-c68d-45ee-91a1-184412af9ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle The formula to calculate the area of a circle is given by:\n",
       "\n",
       "$$\\text{Area} = \\pi \\times r^2$$\n",
       "\n",
       "where $\\pi$ (pi) represents the mathematical constant approximately equal to 3.14159, and $r$ represents the radius of the circle.\n",
       "\n",
       "Please note that the formatting might not render correctly on this platform.$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "text/latex": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f math\n",
    "Area of a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ba597d-3344-4897-9601-28f1f13ad094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Do the same in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243e57f-f70c-4e42-864a-5eb46bcf2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "radius = 5\n",
    "area = math.pi * radius ** 2\n",
    "\n",
    "print(area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f949a1-0ab7-433a-8c5a-16decdac4e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Do the same in Swift and call the function with 5 as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce3f851-85ee-4fe0-96dd-5f2eacbf79b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3788852651.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    func calculateCircleArea(radius: Double) -> Double {\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import Foundation\n",
    "\n",
    "func calculateCircleArea(radius: Double) -> Double {\n",
    "    let area = Double.pi * radius * radius\n",
    "    return area\n",
    "}\n",
    "\n",
    "let radius = 5.0\n",
    "let area = calculateCircleArea(radius: radius)\n",
    "print(area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47119562-d34c-412b-9f51-801490a4a986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Translate the same to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d9f444f-1d8d-43e6-a135-7885d5e86dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.53981633974483\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_circle_area(radius):\n",
    "    area = math.pi * radius ** 2\n",
    "    return area\n",
    "\n",
    "radius = 5\n",
    "area = calculate_circle_area(radius)\n",
    "print(area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304a35e-c9a1-4bd4-9e68-cf3c6bb7c48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
