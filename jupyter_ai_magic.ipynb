{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e6f1e2-9094-4e93-ae75-874260d969f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae97829c-97fe-4c9e-962b-eab08949710f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a17ea2-b5e9-43e2-9a9a-5195ba2231b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd0d438-75e2-4300-9eb2-4e0f7e159e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] MODEL_ID\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -r, --reset                     Clears the conversation transcript used when\n",
      "                                  interacting with an OpenAI chat model\n",
      "                                  provider. Does nothing with other providers.\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc94991-5db6-4ee5-9865-1b594b2a96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `ai21:j1-large`, `ai21:j1-grande`, `ai21:j1-jumbo`, `ai21:j1-grande-instruct`, `ai21:j2-large`, `ai21:j2-grande`, `ai21:j2-jumbo`, `ai21:j2-grande-instruct`, `ai21:j2-jumbo-instruct` |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | `bedrock:amazon.titan-text-express-v1`, `bedrock:ai21.j2-ultra-v1`, `bedrock:ai21.j2-mid-v1`, `bedrock:cohere.command-text-v14` |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | `bedrock-chat:anthropic.claude-v1`, `bedrock-chat:anthropic.claude-v2`, `bedrock-chat:anthropic.claude-instant-v1` |\n",
       "| `anthropic` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `anthropic:claude-v1`, `anthropic:claude-v1.0`, `anthropic:claude-v1.2`, `anthropic:claude-2`, `anthropic:claude-2.0`, `anthropic:claude-instant-v1`, `anthropic:claude-instant-v1.0`, `anthropic:claude-instant-v1.2` |\n",
       "| `anthropic-chat` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `anthropic-chat:claude-v1`, `anthropic-chat:claude-v1.0`, `anthropic-chat:claude-v1.2`, `anthropic-chat:claude-2`, `anthropic-chat:claude-2.0`, `anthropic-chat:claude-instant-v1`, `anthropic-chat:claude-instant-v1.0`, `anthropic-chat:claude-instant-v1.2` |\n",
       "| `azure-chat-openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `cohere:medium`, `cohere:xlarge` |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | `gpt4all:ggml-gpt4all-j-v1.2-jazzy`, `gpt4all:ggml-gpt4all-j-v1.3-groovy`, `gpt4all:ggml-gpt4all-l13b-snoozy` |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai:text-davinci-003`, `openai:text-davinci-002`, `openai:text-curie-001`, `openai:text-babbage-001`, `openai:text-ada-001`, `openai:davinci`, `openai:curie`, `openai:babbage`, `openai:ada` |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai-chat:gpt-3.5-turbo`, `openai-chat:gpt-3.5-turbo-16k`, `openai-chat:gpt-3.5-turbo-0301`, `openai-chat:gpt-3.5-turbo-0613`, `openai-chat:gpt-3.5-turbo-16k-0613`, `openai-chat:gpt-4`, `openai-chat:gpt-4-0314`, `openai-chat:gpt-4-0613`, `openai-chat:gpt-4-32k`, `openai-chat:gpt-4-32k-0314`, `openai-chat:gpt-4-32k-0613` |\n",
       "| `openai-chat-new` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai-chat-new:gpt-3.5-turbo`, `openai-chat-new:gpt-3.5-turbo-16k`, `openai-chat-new:gpt-3.5-turbo-0301`, `openai-chat-new:gpt-3.5-turbo-0613`, `openai-chat-new:gpt-3.5-turbo-16k-0613`, `openai-chat-new:gpt-4`, `openai-chat-new:gpt-4-0314`, `openai-chat-new:gpt-4-0613`, `openai-chat-new:gpt-4-32k`, `openai-chat-new:gpt-4-32k-0314`, `openai-chat-new:gpt-4-32k-0613` |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:text-davinci-003` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:cohere.command-text-v14\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:anthropic.claude-v1\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "\n",
       "anthropic\n",
       "Requires environment variable ANTHROPIC_API_KEY (not set)\n",
       "* anthropic:claude-v1\n",
       "* anthropic:claude-v1.0\n",
       "* anthropic:claude-v1.2\n",
       "* anthropic:claude-2\n",
       "* anthropic:claude-2.0\n",
       "* anthropic:claude-instant-v1\n",
       "* anthropic:claude-instant-v1.0\n",
       "* anthropic:claude-instant-v1.2\n",
       "\n",
       "anthropic-chat\n",
       "Requires environment variable ANTHROPIC_API_KEY (not set)\n",
       "* anthropic-chat:claude-v1\n",
       "* anthropic-chat:claude-v1.0\n",
       "* anthropic-chat:claude-v1.2\n",
       "* anthropic-chat:claude-2\n",
       "* anthropic-chat:claude-2.0\n",
       "* anthropic-chat:claude-instant-v1\n",
       "* anthropic-chat:claude-instant-v1.0\n",
       "* anthropic-chat:claude-instant-v1.2\n",
       "\n",
       "azure-chat-openai\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "cohere\n",
       "Requires environment variable COHERE_API_KEY (not set)\n",
       "* cohere:medium\n",
       "* cohere:xlarge\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable HUGGINGFACEHUB_API_TOKEN (not set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "openai\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai:text-davinci-003\n",
       "* openai:text-davinci-002\n",
       "* openai:text-curie-001\n",
       "* openai:text-babbage-001\n",
       "* openai:text-ada-001\n",
       "* openai:davinci\n",
       "* openai:curie\n",
       "* openai:babbage\n",
       "* openai:ada\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-16k\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "* openai-chat:gpt-3.5-turbo-0613\n",
       "* openai-chat:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-0314\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0314\n",
       "* openai-chat:gpt-4-32k-0613\n",
       "\n",
       "openai-chat-new\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai-chat-new:gpt-3.5-turbo\n",
       "* openai-chat-new:gpt-3.5-turbo-16k\n",
       "* openai-chat-new:gpt-3.5-turbo-0301\n",
       "* openai-chat-new:gpt-3.5-turbo-0613\n",
       "* openai-chat-new:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat-new:gpt-4\n",
       "* openai-chat-new:gpt-4-0314\n",
       "* openai-chat-new:gpt-4-0613\n",
       "* openai-chat-new:gpt-4-32k\n",
       "* openai-chat-new:gpt-4-32k-0314\n",
       "* openai-chat-new:gpt-4-32k-0613\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:text-davinci-003\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a44e0e-5456-4855-aad6-5fbfa3d072d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai:text-davinci-003`, `openai:text-davinci-002`, `openai:text-curie-001`, `openai:text-babbage-001`, `openai:text-ada-001`, `openai:davinci`, `openai:curie`, `openai:babbage`, `openai:ada` |\n"
      ],
      "text/plain": [
       "openai\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai:text-davinci-003\n",
       "* openai:text-davinci-002\n",
       "* openai:text-curie-001\n",
       "* openai:text-babbage-001\n",
       "* openai:text-ada-001\n",
       "* openai:davinci\n",
       "* openai:curie\n",
       "* openai:babbage\n",
       "* openai:ada\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d676697-bc09-4063-9b3c-49ebfb5dff6d",
   "metadata": {},
   "source": [
    "#### Magic in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4246a4f4-18bf-4307-a7f5-918c3e03b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Lists\n",
       "- Lists are mutable, which means they can be changed after their creation.\n",
       "- Lists are ordered, meaning that the items in a list have a specific order and can be accessed by their index.\n",
       "- Lists can contain duplicate elements.\n",
       "- Lists are represented by square brackets [ ].\n",
       "\n",
       "# Tuples\n",
       "- Tuples are immutable, which means they cannot be modified after their creation.\n",
       "- Tuples are ordered and can be accessed by their index.\n",
       "- Tuples can contain duplicate elements.\n",
       "- Tuples are represented by parentheses ( ).\n",
       "\n",
       "# Sets\n",
       "- Sets are mutable and unordered, which means that the items in a set have no guaranteed order.\n",
       "- Sets do not allow duplicate elements.\n",
       "- Sets are represented by curly braces { }.\n",
       "- Sets can perform set operations like union, intersection, and difference efficiently.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-3.5-turbo\n",
    "lists vs tuples vs sets in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f75db4-8b6c-4b47-a8c4-8d4a1754985f",
   "metadata": {},
   "source": [
    "#### Using alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967cb5b0-0701-47d8-94da-a321cd629ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To sort an array in Swift, you can use the `sorted()` function or the `sort()` method. Here is an example:\n",
       "\n",
       "```swift\n",
       "var array = [5, 2, 9, 1, 3]\n",
       "\n",
       "// Using sorted() function\n",
       "let sortedArray = array.sorted()\n",
       "print(sortedArray)  // Output: [1, 2, 3, 5, 9]\n",
       "\n",
       "// Using sort() method\n",
       "array.sort()\n",
       "print(array)  // Output: [1, 2, 3, 5, 9]\n",
       "```\n",
       "\n",
       "Both the `sorted()` function and `sort()` method return a new array with the elements sorted in ascending order. If you want to sort the array in descending order, you can use the `sorted(by:)` function or the `sort(by:)` method, specifying a custom sorting closure. Here is an example:\n",
       "\n",
       "```swift\n",
       "var array = [5, 2, 9, 1, 3]\n",
       "\n",
       "// Sorting in descending order using sorted(by:) function\n",
       "let sortedArray = array.sorted(by: >)\n",
       "print(sortedArray)  // Output: [9, 5, 3, 2, 1]\n",
       "\n",
       "// Sorting in descending order using sort(by:) method\n",
       "array.sort(by: >)\n",
       "print(array)  // Output: [9, 5, 3, 2, 1]\n",
       "```\n",
       "\n",
       "In this case, the `>` (greater than) operator is used as the sorting closure to sort the array in descending order."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Sorting array in Swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66768242-fc92-4cc5-a35f-38db5c45d4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The `AppDelegate` class is a critical part of an iOS application written in Swift. It serves as the delegate for handling and responding to various system-level events and actions that occur during the lifecycle of the app. Here's a brief explanation of the `AppDelegate` in iOS using Swift:\n",
       "\n",
       "- The `AppDelegate` class is automatically created when you create a new iOS project in Xcode. It represents the overall application instance and acts as the entry point for the app's interactions with the system.\n",
       "\n",
       "- The `AppDelegate` class conforms to the `UIApplicationDelegate` protocol, which defines a set of methods that handle important app-level events such as application launch, termination, background execution, memory warning, etc.\n",
       "\n",
       "- The `AppDelegate` contains several methods, such as `application(_:didFinishLaunchingWithOptions:)`, `applicationWillResignActive(_:)`, `applicationDidEnterBackground(_:)`, `applicationWillEnterForeground(_:)`, and `applicationDidBecomeActive(_:)`, among others.\n",
       "\n",
       "- The `application(_:didFinishLaunchingWithOptions:)` method is called when the app finishes launching, and it provides an opportunity to perform any necessary setup or initialization tasks.\n",
       "\n",
       "- The `applicationWillResignActive(_:)` method is called when the app is about to become inactive, often triggered by events like an incoming call or a user opening the Control Center.\n",
       "\n",
       "- The `applicationDidEnterBackground(_:)` method is called when the app enters the background, allowing you to save any necessary data or perform cleanup tasks.\n",
       "\n",
       "- The `applicationWillEnterForeground(_:)` method is called when the app is about to enter the foreground from the background.\n",
       "\n",
       "- The `applicationDidBecomeActive(_:)` method is called when the app becomes active after being in the background.\n",
       "\n",
       "- You can override these methods in the `AppDelegate` class to add your custom code and respond to specific app-level events.\n",
       "\n",
       "- Additionally, the `AppDelegate` class contains the `window` property, which represents the app's main window and is responsible for presenting the user interface.\n",
       "\n",
       "Overall, the `AppDelegate` class is a crucial component of an iOS app, allowing you to handle system-level events and manage the overall behavior and appearance of the application."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "explain AppDelegate in iOS, Swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ff7a8c-dbe0-4004-a115-5b7e4a59c181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A list in Python is a built-in data structure that represents an ordered collection of elements. It can hold items of different data types, such as numbers, strings, or even other lists. Here's an explanation of lists in Python:\n",
       "\n",
       "- Lists are enclosed in square brackets [ ] and each element is separated by a comma.\n",
       "- Lists are mutable, meaning that their elements can be modified after creation. You can add, remove, or change elements within a list.\n",
       "- Lists can contain elements of different data types. For example, a list can have a combination of integers, strings, or even other lists as its elements.\n",
       "- Lists are ordered, which means that the elements have a specific position or index within the list. The indexing starts from 0, where 0 refers to the first element, 1 refers to the second element, and so on.\n",
       "- Lists allow duplicate elements, which means that the same value can appear multiple times in a list.\n",
       "- Lists support various built-in functions and methods to perform operations such as adding elements, removing elements, sorting, and more.\n",
       "- Lists are versatile and commonly used in Python for tasks like storing collections of data, implementing stacks, queues, and other data structures, iterating over elements, and manipulating data.\n",
       "\n",
       "Example:\n",
       "```python\n",
       "my_list = [1, 2, \"hello\", True, [3, 4, 5]]\n",
       "\n",
       "print(my_list[0])  # Output: 1\n",
       "print(my_list[2])  # Output: hello\n",
       "\n",
       "my_list.append(\"world\")\n",
       "print(my_list)  # Output: [1, 2, \"hello\", True, [3, 4, 5], \"world\"]\n",
       "\n",
       "my_list.remove(2)\n",
       "print(my_list)  # Output: [1, \"hello\", True, [3, 4, 5], \"world\"]\n",
       "```\n",
       "\n",
       "In the example above, we create a list `my_list` with various elements. We access specific elements using indexing, add an element using the `append()` method, and remove an element using the `remove()` method."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai gpt-3.5-turbo\n",
    "Explain list in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1138bd7a-c68d-45ee-91a1-184412af9ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle The formula to calculate the area of a circle is given by:\n",
       "\n",
       "$$\\text{Area} = \\pi \\times r^2$$\n",
       "\n",
       "where $\\pi$ (pi) represents the mathematical constant approximately equal to 3.14159, and $r$ represents the radius of the circle.\n",
       "\n",
       "Please note that the formatting might not render correctly on this platform.$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "text/latex": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f math\n",
    "Area of a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ba597d-3344-4897-9601-28f1f13ad094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Do the same in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243e57f-f70c-4e42-864a-5eb46bcf2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "radius = 5\n",
    "area = math.pi * radius ** 2\n",
    "\n",
    "print(area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f949a1-0ab7-433a-8c5a-16decdac4e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Do the same in Swift and call the function with 5 as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce3f851-85ee-4fe0-96dd-5f2eacbf79b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3788852651.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    func calculateCircleArea(radius: Double) -> Double {\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import Foundation\n",
    "\n",
    "func calculateCircleArea(radius: Double) -> Double {\n",
    "    let area = Double.pi * radius * radius\n",
    "    return area\n",
    "}\n",
    "\n",
    "let radius = 5.0\n",
    "let area = calculateCircleArea(radius: radius)\n",
    "print(area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47119562-d34c-412b-9f51-801490a4a986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Translate the same to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d9f444f-1d8d-43e6-a135-7885d5e86dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.53981633974483\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_circle_area(radius):\n",
    "    area = math.pi * radius ** 2\n",
    "    return area\n",
    "\n",
    "radius = 5\n",
    "area = calculate_circle_area(radius)\n",
    "print(area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59208d7-64ea-435d-bf2c-6735b5fcc719",
   "metadata": {},
   "source": [
    "#### More magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf899a35-6510-42b7-b481-9ee0ea8de840",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "a, b = 10, '1'\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f5e1b7-7682-4b58-98ee-b9d9a7533758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The error message indicates a `TypeError` occurring in the code. Here's an explanation of the error:\n",
       "\n",
       "- The error specifically states: `TypeError: unsupported operand type(s) for +: 'int' and 'str'`.\n",
       "- This error is raised when you try to perform an operation between two objects of incompatible types.\n",
       "- In this case, you are trying to perform the addition operation (`+`) between an `int` and a `str`.\n",
       "- In Python, the `+` operator is used for addition when used with numbers, or concatenation when used with strings.\n",
       "- However, in this scenario, the types of `a` and `b` are incompatible for addition, as `a` is an `int` representing the number 10, and `b` is a `str` representing the string '1'.\n",
       "- Since the `+` operator is ambiguous in this context, Python raises a `TypeError` to indicate the unsupported operand types for addition.\n",
       "\n",
       "To resolve the error, you need to ensure that the operands for the `+` operator are of compatible types. If you want to concatenate the string representation of `a` with `b`, you can use `str(a)` to convert `a` to a string before performing the addition:\n",
       "\n",
       "```python\n",
       "a, b = 10, '1'\n",
       "result = str(a) + b\n",
       "print(result)  # Output: '101'\n",
       "```\n",
       "\n",
       "By converting `a` to a string using `str(a)`, you can concatenate it with `b` correctly and avoid the `TypeError`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Explain error {Err[20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1272a99f-5473-4cf1-8d7b-87f79faf0b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Based on the error description, if you want to concatenate the integer `a` with the string `b`, you need to convert `a` to a string before performing the addition. Here's the corrected code:\n",
       "\n",
       "```python\n",
       "a, b = 10, '1'\n",
       "result = str(a) + b\n",
       "print(result)  # Output: '101'\n",
       "```\n",
       "\n",
       "By converting `a` to a string using `str(a)`, you can concatenate it with `b` without encountering the `TypeError` and get the desired output."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Give me the correct code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "937098e9-64c0-4c1b-8947-4a7c2f60c13d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (1334284701.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    a = \"Hello\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "a = \"Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "235505af-db03-4ac1-ad5f-eb330f217d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The error message indicates a `SyntaxError` occurring in the code. Here's an explanation of the error:\n",
       "\n",
       "- The error message specifically states: `SyntaxError: unterminated string literal (detected at line 1)`.\n",
       "- This error is raised when a string literal (enclosed in quotes) is not properly terminated.\n",
       "- In this case, the syntax error is detected at line 1, specifically at the beginning of the string assignment.\n",
       "- The cause of the error is that the string declaration is missing the closing quote, resulting in an unterminated string literal.\n",
       "- The opening quote is present, as indicated by the caret (^) beneath it in the error message.\n",
       "- However, the closing quote is missing, causing the interpreter to encounter a syntax error.\n",
       "\n",
       "To resolve the error, you need to ensure that all string literals in your code have both an opening and closing quote. In this case, you should add the missing closing quote. For example:\n",
       "\n",
       "```python\n",
       "a = \"Hello\"\n",
       "```\n",
       "\n",
       "By adding the closing quote at the end of the string, you will resolve the `SyntaxError` and properly terminate the string literal."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai error chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "152ca055-518f-4b4d-9d56-170c995d3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [n**2 for n in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9fa959-ecf4-40a0-8aad-7c76aba95440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca65203d-4536-473a-b315-e2cb411e87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The code `x = [n**2 for n in range(10)]` is a list comprehension in Python. Here's an breakdown of its functionality:\n",
       "\n",
       "- The expression `[n**2 for n in range(10)]` is enclosed within square brackets, representing a list.\n",
       "- This list comprehension creates a new list called `x` that contains the square of each number in the range from 0 to 9 (exclusive).\n",
       "- The syntax `n**2` calculates the square of `n`, where `n` iterates through each element in the range from 0 to 9.\n",
       "- The `for n in range(10)` part specifies the loop that iterates over the range of numbers.\n",
       "- The loop assigns each value of `n` from the range to the expression `n**2`, generating the square for each iteration.\n",
       "- After the iteration completes, the resulting list of squared values is assigned to the variable `x`.\n",
       "\n",
       "Example output:\n",
       "If we print the value of `x` after executing the code, we would obtain the following output:\n",
       "\n",
       "```python\n",
       "x = [n**2 for n in range(10)]\n",
       "print(x)\n",
       "```\n",
       "\n",
       "Output:\n",
       "```\n",
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
       "```\n",
       "\n",
       "In this case, `x` is assigned a list containing the squares of the numbers from 0 to 9. The resulting list, when printed, shows the sequence of numbers `[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Explain this code: {In[27]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "848dec4d-cc9e-445b-a46b-82b336d36b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7862e24-7bb4-4f0d-8a5e-307236f2bb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7af3255d-00d4-43a5-baf0-a12badae01e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a function in Python that takes an argument `n` and returns a sequence of numbers based on the pattern specified: [0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91]:\n",
       "\n",
       "```python\n",
       "def number_sequence(n):\n",
       "    sequence = []\n",
       "    for i in range(n):\n",
       "        num = (i * (i + 1)) // 2\n",
       "        sequence.append(num)\n",
       "    return sequence\n",
       "\n",
       "result = number_sequence(14)\n",
       "print(result)\n",
       "```\n",
       "\n",
       "Output:\n",
       "\n",
       "```\n",
       "[0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91]\n",
       "```\n",
       "\n",
       "In this example, the function `number_sequence` takes an argument `n`, which determines the length of the sequence. The function generates the numbers in the sequence using the formula `num = (i * (i + 1)) // 2`, where `i` iterates through the range from 0 to `n-1`. Each number is then appended to the `sequence` list. Finally, the function returns the generated sequence.\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Define a function that takes an argument and returns the sequence of numbers: {Out[34]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19f0015e-cd41-4b3c-a754-2f60c491ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_sequence(n):\n",
    "    sequence = []\n",
    "    for i in range(n):\n",
    "        num = (i * (i + 1)) // 2\n",
    "        sequence.append(num)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "740f63f8-d7e2-45ed-9a79-6d58a33fe7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_sequence(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dfd9d9-1b92-47d3-b6f2-cd0ebb11b2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
